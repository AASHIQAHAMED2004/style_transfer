{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f54b4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "db27d5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device= torch.device(\"cuda\"if torch.cuda.is_available else \"cpu\")\n",
    "image_size = 365\n",
    "\n",
    "epoches= 10000\n",
    "learning_rate= 0.001\n",
    "alpha= 1\n",
    "beta=0.01\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9277a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "  def __init__(self) :\n",
    "    super(VGG,self).__init__()\n",
    "    #we are chossing the first conv layer after the max pooling\n",
    "    self.chosen_features = ['0','5','10','19','28']\n",
    "    #we are slelcting only upto 28 layers(29-1) for our model\n",
    "    self.model= models.vgg19(pretrained=True).features[:29]\n",
    "\n",
    "  def forward(self,x):\n",
    "    #getting chosen feature layers from model\n",
    "    features=[]\n",
    "    for layer_num,layer in enumerate(self.model):\n",
    "      x=layer(x)\n",
    "      if str(layer_num) in self.chosen_features:\n",
    "        features.append(x)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a169527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are loading unsquzeeing the image and moving it to device ie. GPU or CPU\n",
    "def load_image(image_name):\n",
    "  image=Image.open(image_name)\n",
    "  image=loader(image).unsqueeze(0)\n",
    "  return image.to (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa1eb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size,image_size)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b017125",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image=load_image(\"mona_lisa.PNG\")\n",
    "style_image=load_image(\"stary_nights.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3cdff2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 365, 365])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=VGG().to(device).eval()\n",
    "generated=original_image.clone().requires_grad_(True)\n",
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6699526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting optimizer\n",
    "optimizer=optim.Adam([generated],lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d9783594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(784119.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "100 tensor(55781.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "200 tensor(33027.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "300 tensor(23847.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "400 tensor(17558.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "500 tensor(12659.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "600 tensor(8840.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "700 tensor(6102.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "800 tensor(4351.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "900 tensor(3338.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1000 tensor(2775.9060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1100 tensor(2446.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1200 tensor(2230.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1300 tensor(2069.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1400 tensor(1938.3173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1500 tensor(1828.8344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1600 tensor(1734.5181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1700 tensor(1651.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1800 tensor(1578.1473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1900 tensor(1512.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2000 tensor(1453.2474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2100 tensor(1398.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2200 tensor(1348.7448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2300 tensor(1302.0909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2400 tensor(1258.6061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2500 tensor(1217.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2600 tensor(1179.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2700 tensor(1144.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2800 tensor(1110.2690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2900 tensor(1078.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3000 tensor(1047.3378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3100 tensor(1018.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3200 tensor(990.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3300 tensor(963.3334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3400 tensor(937.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3500 tensor(912.8319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3600 tensor(888.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3700 tensor(865.9595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3800 tensor(843.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3900 tensor(821.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4000 tensor(801.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4100 tensor(780.5953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4200 tensor(760.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4300 tensor(741.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4400 tensor(723.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4500 tensor(705.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4600 tensor(687.7369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4700 tensor(671.0113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4800 tensor(655.9949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4900 tensor(639.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5000 tensor(623.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5100 tensor(609.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5200 tensor(595.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5300 tensor(581.4423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5400 tensor(569.8566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5500 tensor(556.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5600 tensor(544.1624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5700 tensor(531.8341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5800 tensor(522.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5900 tensor(509.0914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6000 tensor(499.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6100 tensor(491.6456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6200 tensor(479.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6300 tensor(469.2836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6400 tensor(461.3029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6500 tensor(452.2262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6600 tensor(443.2438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6700 tensor(435.5177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6800 tensor(431.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6900 tensor(421.5327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7000 tensor(417.5245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7100 tensor(406.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7200 tensor(400.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7300 tensor(394.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7400 tensor(388.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7500 tensor(383.9003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7600 tensor(380.9063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7700 tensor(372.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7800 tensor(367.7849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7900 tensor(362.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8000 tensor(362.7326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8100 tensor(353.6311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8200 tensor(349.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8300 tensor(345.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8400 tensor(342.0910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8500 tensor(338.9545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8600 tensor(334.7813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8700 tensor(333.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8800 tensor(328.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8900 tensor(326.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9000 tensor(323.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9100 tensor(320.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9200 tensor(317.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9300 tensor(316.4935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9400 tensor(324.6532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9500 tensor(310.1441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9600 tensor(307.9188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9700 tensor(310.3055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9800 tensor(304.8971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9900 tensor(303.4130, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "for steps in range(epoches):\n",
    "  generated_features=model(generated)\n",
    "  original_features=model(original_image)\n",
    "  style_features=model(style_image)\n",
    "\n",
    "  style_loss = original_loss = 0\n",
    "\n",
    "  for gen_features,orgin_features,sty_features in zip(generated_features,original_features,style_features):\n",
    "    batch_size,channel,height,width=gen_features.shape\n",
    "    original_loss += torch.mean((gen_features-orgin_features)**2)\n",
    "\n",
    "    #compute gram matrix\n",
    "    G = gen_features.view(channel,height*width).mm(gen_features.view(channel,height*width).t())\n",
    "    \n",
    "    A = sty_features.view(channel,height*width).mm(sty_features.view(channel,height*width).t())\n",
    "\n",
    "    style_loss += torch.mean((G-A)**2)\n",
    "\n",
    "\n",
    "  total_loss = alpha * original_loss + beta * style_loss\n",
    "  optimizer.zero_grad()\n",
    "  total_loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if steps % 100 == 0:\n",
    "    print(steps,total_loss)\n",
    "    save_image(generated,\"genarated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ffae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA_GPT",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
